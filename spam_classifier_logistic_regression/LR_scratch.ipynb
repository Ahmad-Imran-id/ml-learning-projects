{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375e9617-6f89-49be-8d18-55e6fc8d9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy,math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6de477-f97d-4de8-aa92-542177a814c4",
   "metadata": {},
   "source": [
    "The last column of this dataset denotes whether the e-mail was \n",
    "considered spam (1) or not (0).  \n",
    "Most of the attributes indicate whether a particular word or\n",
    "character was frequently occuring in the e-mail\n",
    "\n",
    "We will be using this dataset to train a model to make predictions if an email is consided spam or not when presennted with these atributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6de287-75e4-4ccd-8a24-02ebd73dac08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.64</th>\n",
       "      <th>0.64.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.32</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>...</th>\n",
       "      <th>0.41</th>\n",
       "      <th>0.42</th>\n",
       "      <th>0.43</th>\n",
       "      <th>0.778</th>\n",
       "      <th>0.44</th>\n",
       "      <th>0.45</th>\n",
       "      <th>3.756</th>\n",
       "      <th>61</th>\n",
       "      <th>278</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  0.64  0.64.1  0.1  0.32   0.2   0.3   0.4   0.5   0.6  ...  0.41  \\\n",
       "0  0.21  0.28    0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "1  0.06  0.00    0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "2  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "3  0.00  0.00    0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00    0.00  0.0  1.85  0.00  0.00  1.85  0.00  0.00  ...  0.00   \n",
       "\n",
       "    0.42  0.43  0.778   0.44   0.45  3.756   61   278  1  \n",
       "0  0.132   0.0  0.372  0.180  0.048  5.114  101  1028  1  \n",
       "1  0.143   0.0  0.276  0.184  0.010  9.821  485  2259  1  \n",
       "2  0.137   0.0  0.137  0.000  0.000  3.537   40   191  1  \n",
       "3  0.135   0.0  0.135  0.000  0.000  3.537   40   191  1  \n",
       "4  0.223   0.0  0.000  0.000  0.000  3.000   15    54  1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('spambase.data')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232d886d-ad1c-4014-8553-5f42fba64f3a",
   "metadata": {},
   "source": [
    "# Defining values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "171d2f47-0755-4585-8db2-f46d50ed9425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "4595    0\n",
       "4596    0\n",
       "4597    0\n",
       "4598    0\n",
       "4599    0\n",
       "Name: 1, Length: 4600, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=df.drop(columns=['1'])\n",
    "y_train=df['1']\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db0b367a-5d85-4aa8-9233-d84487e2ce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600,)\n",
      "(4600, 57)\n"
     ]
    }
   ],
   "source": [
    "X_train=np.array(X_train)\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c130c8c-7eba-4860-a793-6fa1e3359bc4",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c826684-dfec-4c8e-9acc-884055ee3b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function for computing cost for logistic regression\n",
    "def sigmoid(z): \n",
    "    z=np.clip(z,-500,500)\n",
    "    g=1/(1+np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44764cd1-9e69-41dc-adde-59d113b12ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling function to make sure gradient decent runs smoothly\n",
    "def feature_scaling(x):\n",
    "    mu=np.mean(x,axis=0)\n",
    "    sigma=np.std(x,axis=0)\n",
    "    x_scaled=(x-mu)/sigma\n",
    "    return x_scaled,mu,sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f4ccbb-57c7-4b91-b846-93999bf2a053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing cost for logistic regression using vectorization\n",
    "def compute_cost(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    z=x @ w+b\n",
    "    fwb=sigmoid(z)\n",
    "    fwb=np.clip(fwb,1e-15,1-1e-15)\n",
    "    cost=(-1/m)*np.sum(y*np.log(fwb)+(1-y)*np.log(1-fwb))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cadeb86-bea5-4987-baec-70498287d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing gradient for logistic regression\n",
    "def compute_gradient(x,y,w,b):\n",
    "    m=x.shape[0]\n",
    "    z=x @ w+b\n",
    "    fwb=sigmoid(z)\n",
    "    fwb=np.clip(fwb,1e-15,1-1e-15)\n",
    "    err=fwb-y\n",
    "    dj_dw=(1/m)*x.T @ err \n",
    "    dj_db=(1/m)*np.sum(err)\n",
    "\n",
    "    return dj_dw,dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf50da02-51d6-4637-b736-262e84f91607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Gradient descent function for finding value of w and b\n",
    "def gradient_decent(x,y,w_in,b_in,alpha,itr,compute_cost,compute_gradient):\n",
    "    w=np.copy(w_in)\n",
    "    b=b_in\n",
    "    J_hist=[compute_cost(x,y,w,b)] #list for storing cost at each iteration\n",
    "    print(f'Iteration :    0: Cost: {J_hist[-1]:8.4f}')\n",
    "\n",
    "    for i in range (itr):\n",
    "        #main formula for gradient descent\n",
    "        dj_dw,dj_db=compute_gradient(x,y,w,b)\n",
    "        w-=alpha*dj_dw\n",
    "        b-=alpha*dj_db\n",
    "\n",
    "        if i<10000: #appending J_hist \n",
    "            J_hist.append(compute_cost(x,y,w,b))\n",
    "\n",
    "        #Printing iteration and cost at 10% iteration\n",
    "        if (i+1)% max(1,itr//10)==0:\n",
    "            print(f'Iteration : {i+1:4d}: Cost: {J_hist[-1]:8.4f}')\n",
    "\n",
    "    return w,b,J_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d31a2c-cfe0-4354-8788-7f2e777559c8",
   "metadata": {},
   "source": [
    "# Running Gradient Descent for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba93fe7c-a1ec-41f9-a9d2-af92d457a1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :    0: Cost:   0.6931\n",
      "Iteration :  500: Cost:   0.2029\n",
      "Iteration : 1000: Cost:   0.2015\n",
      "Iteration : 1500: Cost:   0.2007\n",
      "Iteration : 2000: Cost:   0.2002\n",
      "Iteration : 2500: Cost:   0.1998\n",
      "Iteration : 3000: Cost:   0.1995\n",
      "Iteration : 3500: Cost:   0.1993\n",
      "Iteration : 4000: Cost:   0.1991\n",
      "Iteration : 4500: Cost:   0.1989\n",
      "Iteration : 5000: Cost:   0.1988\n"
     ]
    }
   ],
   "source": [
    "#Specifying required values for gradient decent\n",
    "n=X_train.shape[1]\n",
    "alpha=10\n",
    "itr=5000\n",
    "X_scaled,mu,sigma=feature_scaling(X_train)\n",
    "w_in=np.zeros((n,))\n",
    "b_in=0.0\n",
    "\n",
    "#running gradient descent\n",
    "w_final,b_final,J_hist=gradient_decent(X_scaled,y_train,w_in,b_in,alpha,itr,compute_cost,compute_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ee997-c534-4141-b44e-653d846991a0",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79791b3c-502e-4125-a032-5802aaf5114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for testing model predictions\n",
    "def predict(x,w_final,b_final):\n",
    "    z=x@w_final+b_final\n",
    "    fwb=sigmoid(z)\n",
    "    predictions=(fwb>=0.51).astype(int)  #stores prediction values as 0 or 1\n",
    "    labels=np.where(predictions==1,'Spam','Not Spam') #labels store Spam or Not spam\n",
    "\n",
    "    return predictions,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6c636fc-4d99-4a3c-ab3b-fe5de9ffe802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model acucuracy= 93.21739130434783%\n"
     ]
    }
   ],
   "source": [
    "# testing model accuracy\n",
    "preds,lab=predict(X_scaled,w_final,b_final)\n",
    "accuracy = np.mean(preds == y_train) * 100\n",
    "print(f'Model acucuracy= {accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "007acd1d-29fc-4a17-8fc6-e96b36b6114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model prediction: Not Spam   : Actual value of y: Not Spam  \n",
      "Model prediction: Not Spam   : Actual value of y: Not Spam  \n",
      "Model prediction: Spam       : Actual value of y: Spam      \n",
      "Model prediction: Spam       : Actual value of y: Spam      \n",
      "Model prediction: Spam       : Actual value of y: Spam      \n",
      "Model prediction: Spam       : Actual value of y: Spam      \n",
      "Model prediction: Not Spam   : Actual value of y: Not Spam  \n",
      "Model prediction: Spam       : Actual value of y: Spam      \n",
      "Model prediction: Not Spam   : Actual value of y: Not Spam  \n",
      "Model prediction: Not Spam   : Actual value of y: Not Spam  \n"
     ]
    }
   ],
   "source": [
    "# Comparing some model predictions with actual vlaue in dataset\n",
    "\n",
    "X_test=(X_train[0:3000:100,:]-mu)/sigma # Getting test data for model evaluation while feature scaling it\n",
    "y_test=y_train[0:3000:100]\n",
    "\n",
    "\n",
    "predictions,labels=predict(X_test,w_final,b_final)\n",
    "y_labels=np.where(y_test==1,'Spam','Not Spam')\n",
    "\n",
    "indexes=np.random.choice(len(labels),10,replace=False)\n",
    "for i in indexes:\n",
    "    print(f'Model prediction: {labels[i]:<10} : Actual value of y: {y_labels[i]:<10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985b4e6-f35d-4610-9fe7-a643d9121873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
